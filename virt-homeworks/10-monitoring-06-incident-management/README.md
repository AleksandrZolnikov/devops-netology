## Домашнее задание к занятию "10.06. Инцидент-менеджмент"

### Задание 1

Составьте постмотрем, на основе реального сбоя системы Github в 2018 году.

Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).  

|       |       |
|:-------|:-------|
|1. Краткое описание инцидента  |Деградация части сервисов, начавшаяся в 22:52 UTC 21 октября 2018, и длившаяся 24 часа 11 минут. В результате сбоя множество систем отображало устаревшие или поврежденные данные. Пользовательские данные при этом потеряны не были.|
|2. Предшествующие события  |Плановые работы по техническому обслуживанию по замене вышедшего из строя оптического оборудования 100G.|
|3. Причина инцидента  |Потеря связи на 43 секунды между сетевым центром на восточном побережье США и основным ЦОД на восточном побережье США.|
|4. Воздействие        |Инцидент повлиял на метаданные веб-сайтов, хранящиеся в базах данных MySQL: Issue и push. Невозможно было создать issue и push.|
|5. Обнаружение        |Обнаружено инженерами, обрабатывающими входящие уведомления систем монторинга.|
|6. Реакция            |Инцидент устранен за 24 часа 11 минут.|
|7. Восстановление     |Восстановление БД из резервных копий, далее репликация данных с активных рабочих серверов БД.|
|8. Таймлайн.|22:52 21.10.2018 UTC - сбой соединения между ЦОД Восточного и Западного побережья США.
22:54 21.10.2018 UTC - обнаружение сбоя.
23:02 21.10.2018 UTC - определение причины сбоя, связанной с непредвиденным состоянием БД.
23:09 21.10.2018 UTC - присвоение событию желтого статуса.
23:11 21.10.2018 UTC - присвоение событию красного статуса.
23:13 21.10.2018 UTC - привлечение дополнительных специалистов, детальное изучение ситуации.
23:19 21.10.2018 UTC - принятие решения об остановке запущенных задач, пишущих метаданные.
00:05 22.10.2018 UTC - разработка плана восстановления.
00:41 22.10.2018 UTC - начат процесс восстановления кластеров из резервной копии.
06:51 22.10.2018 UTC - окончание процесса восстановления, начало процесса репликации.
07:46 22.10.2018 UTC - опубликовано сообщение с описанием сбоя в блоге.
11:12 22.10.2018 UTC - окончание репликации кластеров.
13:15 22.10.2018 UTC - выделены дополнительные MySQL реплики для уменьшения задержи репликации на чтение.
16:24 22.10.2018 UTC - окончание синхронизации реплик. Статус сервисов сохранен на красном уровне, чтобы закончить процессы, накопившиеся за время сбоя.
16:45 22.10.2018 UTC - подтверждение восстановления данных, статус сайта изменен на зеленый.|
|9. Последующие действия|Устранение оставшихся несоответсвий в данных.  <br>Изменение конфигурации Orchestrator.|


## Задача повышенной сложности


- 3.22 PM - db2 Kafka не работает, служба не работает 
- 3.23 PM - перезапуск не помог, откат на предыдущую версию не помог
- 3.24 PM - наблюдается много ошибок в логах Kafka, наблюдается сбой на приложениях андройд у клиентов и в веб приложении
- 3.27 PM - проблема может быть с кластером Mesos 
- 3.29 PM - нужно подготовить уведомления для клиентов и черновик опубликовать в канале Слак
- 3.30 PM - опубликовано уведомления для клиентов на на странице и Twitter 
- 3.36 PM - возможно нужно перезапустить Mesos 
- 3.39 PM - пока воздержимся от перезвпуска 
- 3.41 PM - mesos agent 2 и 3 недоступен 
- 3.43 PM - остался 1 агент кластера и память постоянно растет, Kafka то подымается, то падает 
- 3.45 PM - есть еще 1 кластерт Месос в другом регионе, и мы можем тогда перезарустить кластер Месос 
- 3.48 PM - Принято решение перезапустить агент 3 
- 3.49 PM - Linux OOM Killer сработал на агенте 1 
- 3.52 PM - Принято решение перезапустить агент 2 
- 3.53 PM - Агент 3 вернулся и работает, принято решение запуска контейнеров вручную на агенте 3 
- 3.55 PM - контейнеры не запускаются и выводят 137 ошибку 
- 3.57 PM - выяснили, это из-за Linux OOM Killer 
- 3.58 PM - выяснили предел памяти 130MB, решили вручную удвоить размер памяти, 
- 4.05 PM - это помогло и контейнеры запускаются без ошибок, консоль Maraton тоже показывает что все выглядит хорошо. Мобильные приложения клинтов работаю, но пока есть проблема в веб интерфейсе 
- 4.06 PM - отстают данные из-за простоя Kafka
- 4.07 PM - нужно подождать данных, которые отстали. Составить черновик сообщения для клиентов 
- 4.08 PM - опубликовать на странице и Twitter сообщение для клиентов. Всё выглядит хорошо, идет восстановление системы
- 4.09 PM - добавили список задач, для предотвращения данных инцидентов